fruit: ???
task_lm: roberta-large
is_mask_lm: null
compute_zscore: true
incorrect_coeff: 180.0
correct_coeff: 200.0
dataset: sst-2
dataset_seed: 1
base_path: ./data
num_shots: 16
policy_lm: distilgpt2
hidden_size: 2048
logit_bias: 0.0
fluent: false
fluent_top_k: 20
max_decoding_length: 5
eos_token_id: null
prompt_length: 5
prompt_train_batch_size: 16
prompt_infer_batch_size: 1
source_str: <|endoftext|>
sql_loss_impl: v2_v2r_v3_v3r
training_mode: sql-onpolicy
mix_strategy: null
target_update_method: polyak
target_update_steps: null
target_learning_rate: 0.001
reward_shaping: true
reward_shaping_old_min: 0.0
reward_shaping_old_max: 1.0
reward_shaping_new_min: 0.0
reward_shaping_new_max: 5.0
top_k: 256
top_p: 1.0
num_beams: 1
train_batch_size: 16
train_shuffle: false
train_drop_last: true
num_train_epochs: 1
max_train_steps: 6000
training_device: cpu
dpo_training: false
do_eval: true
eval_batch_size: 2
eval_steps: 10
do_save: true
save_dir: ./outputs
save_steps: 100
learning_rate: 5.0e-05
gradient_clip: true
gradient_clip_norm: 5.0
checkpoint_path: null
random_seed: null
report_to_wandb: false
project_name: rl-prompt
run_name: roberta-large-rl
dpo_loss_config:
  dpo_training: false
  name: ipo
  beta: 1.0
  reference_free: false
  label_smoothing: 0.0
  reference_learning_rate: 0.001
  multi_optimize: false
  nondominate_punishment: null
  epsilon: 0.1
model_path: null
algorithm_name: ParetoPrompt-IPO
load_step: 0
dominate_evaluate_num: 2
temperature: 0.3
initial_file: ./sts_initial_review.txt
