{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting pygmo\n",
      "  Downloading pygmo-v2.19.0.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pygmo from https://files.pythonhosted.org/packages/e2/12/090ba61479f60d5177a0048736d09dc028b2d65063ed44cb952df506336f/pygmo-v2.19.0.tar.gz does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pygmo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominating hypervolume is: 0.17749999225139623\n"
     ]
    }
   ],
   "source": [
    "import pygmo as pg\n",
    "import torch\n",
    "# Example Pareto front: A list of 3D points (x, y, z)\n",
    "pareto_front =     torch.tensor([[-0.5, -0.7, -0.2],[-0.7, -0.5, -0.45]])\n",
    "\n",
    "\n",
    "# Reference point (should be worse than any point in the Pareto front)\n",
    "reference_point = [.0, .0, .0]\n",
    "\n",
    "# Create a hypervolume object\n",
    "hv = pg.hypervolume(pareto_front)\n",
    "\n",
    "# Compute the hypervolume w.r.t. the reference point\n",
    "hypervolume_value = hv.compute(reference_point)\n",
    "\n",
    "print(f\"The dominating hypervolume is: {hypervolume_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dominating hypervolume is: 0.006999999999999987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_3d_hypervolume(pareto_front, reference_point):\n",
    "    # Sort Pareto front by the first objective (x-axis)\n",
    "    sorted_front = sorted(pareto_front, key=lambda x: x[0])\n",
    "    \n",
    "    # Initialize hypervolume\n",
    "    hypervolume = 0.0\n",
    "    \n",
    "    # Iterate over the Pareto front points\n",
    "    for i in range(len(sorted_front)):\n",
    "        if i == 0:\n",
    "            x_len = reference_point[0] - sorted_front[i][0]\n",
    "        else:\n",
    "            x_len = sorted_front[i - 1][0] - sorted_front[i][0]\n",
    "        \n",
    "        y_len = reference_point[1] - sorted_front[i][1]\n",
    "        z_len = reference_point[2] - sorted_front[i][2]\n",
    "        \n",
    "        volume = x_len * y_len * z_len\n",
    "        hypervolume += volume\n",
    "    \n",
    "    return hypervolume\n",
    "\n",
    "# Example Pareto front: a list of 3D points (x, y, z)\n",
    "pareto_front = np.array([\n",
    "    [0.5, 0.7, 0], [0.7, 0.5, 0]\n",
    "])\n",
    "\n",
    "# Reference point (should be worse than any point in the Pareto front)\n",
    "reference_point = np.array([1.0, 1.0, 1.0])\n",
    "\n",
    "# Compute the hypervolume\n",
    "hypervolume_value = calculate_3d_hypervolume(pareto_front, reference_point)\n",
    "\n",
    "print(f\"The dominating hypervolume is: {hypervolume_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominating volume in 3D: tensor(504.)\n"
     ]
    }
   ],
   "source": [
    "def calculate_dominating_volume_3d(pareto_front, ref_point):\n",
    "    \"\"\"\n",
    "    Calculate the dominating volume of the Pareto front with respect to a reference point in 3D.\n",
    "\n",
    "    :param pareto_front: Torch tensor of size N*3 containing points in the Pareto front (N points, 3 objectives).\n",
    "    :param ref_point: Torch tensor of size 3 representing the reference point.\n",
    "    :return: Dominating volume of the Pareto front in 3D.\n",
    "    \"\"\"\n",
    "    # Sort Pareto front based on the first objective (ascending order)\n",
    "    sorted_pareto_front = pareto_front[pareto_front[:, 0].argsort()]\n",
    "    \n",
    "    # Initialize dominating volume\n",
    "    dominating_volume = 0.0\n",
    "    \n",
    "    # Initialize the upper corner of the volume\n",
    "    upper_corner = ref_point.clone()\n",
    "    \n",
    "    # Iterate through sorted Pareto front\n",
    "    for point in sorted_pareto_front:\n",
    "        # Calculate the width, height, and depth of the cuboid\n",
    "        width = point[0] - upper_corner[0]\n",
    "        height = point[1] - upper_corner[1]\n",
    "        depth = point[2] - upper_corner[2]\n",
    "        \n",
    "        # If width, height, or depth are negative, it means the point is not dominated in that direction\n",
    "        # and we should skip this point.\n",
    "        if width <= 0 or height <= 0 or depth <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Update dominating volume by adding the volume of the cuboid\n",
    "        dominating_volume += width * height * depth\n",
    "        \n",
    "        # Update the upper corner for the next cuboid\n",
    "        upper_corner[0] = point[0]\n",
    "\n",
    "    return dominating_volume\n",
    "\n",
    "# Example usage\n",
    "import torch\n",
    "\n",
    "N = 5  # Number of points in the Pareto front\n",
    "pareto_front = torch.tensor([[7, 8, 9]])  # Random points in 3D space\n",
    "ref_point = torch.tensor([.0, .0, .0])  # Reference point in 3D space\n",
    "\n",
    "dom_volume = calculate_dominating_volume_3d(pareto_front, ref_point)\n",
    "print(\"Dominating volume in 3D:\", dom_volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "QhullError",
     "evalue": "QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)\n\nWhile executing:  | qhull i Qt\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 1636645736  incidence  Qtriangulate  _pre-merge  _zero-centrum\n  _max-width  6  Error-roundoff 1.2e-14  _one-merge 8.7e-14\n  _near-inside 4.4e-13  Visible-distance 2.5e-14  U-max-coplanar 2.5e-14\n  Width-outside 5e-14  _wide-facet 1.5e-13  _maxoutside 1e-13\n\nprecision problems (corrected unless 'Q0' or an error)\n      4 degenerate hyperplanes recomputed with gaussian elimination\n      4 nearly singular or axis-parallel hyperplanes\n      4 zero divisors during back substitute\n      4 zero divisors during gaussian elimination\n\nThe input to qhull appears to be less than 3 dimensional, or a\ncomputation has overflowed.\n\nQhull could not construct a clearly convex simplex from points:\n- p3(v4):     2     3     4\n- p1(v3):     4     5     6\n- p2(v2):     7     8     9\n- p0(v1):     1     2     3\n\nThe center point is coplanar with a facet, or a vertex is coplanar\nwith a neighboring facet.  The maximum round off error for\ncomputing distances is 1.2e-14.  The center point, facets and distances\nto the center point are as follows:\n\ncenter point      3.5      4.5      5.5\n\nfacet p1 p2 p0 distance= -4.4e-16\nfacet p3 p2 p0 distance= -4.4e-16\nfacet p3 p1 p0 distance= -4.4e-16\nfacet p3 p1 p2 distance= -4.4e-16\n\nThese points either have a maximum or minimum x-coordinate, or\nthey maximize the determinant for k coordinates.  Trial points\nare first selected from points that maximize a coordinate.\n\nThe min and max coordinates for each dimension are:\n  0:         1         7  difference=    6\n  1:         2         8  difference=    6\n  2:         3         9  difference=    6\n\nIf the input should be full dimensional, you have several options that\nmay determine an initial simplex:\n  - use 'QJ'  to joggle the input and make it full dimensional\n  - use 'QbB' to scale the points to the unit cube\n  - use 'QR0' to randomly rotate the input for different maximum points\n  - use 'Qs'  to search all points for the initial simplex\n  - use 'En'  to specify a maximum roundoff error less than 1.2e-14.\n  - trace execution with 'T3' to see the determinant for each point.\n\nIf the input is lower dimensional:\n  - use 'QJ' to joggle the input and make it full dimensional\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\n    pick the coordinate with the least range.  The hull will have the\n    correct topology.\n  - determine the flat containing the points, rotate the points\n    into a coordinate plane, and delete the other coordinates.\n  - add one or more points to make the input full dimensional.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQhullError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Example points (replace with your own data)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m], [\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m9\u001b[39m], [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]])\n\u001b[0;32m---> 14\u001b[0m     volume \u001b[38;5;241m=\u001b[39m \u001b[43mdominating_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDominating volume:\u001b[39m\u001b[38;5;124m\"\u001b[39m, volume)\n",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mdominating_volume\u001b[0;34m(points)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdominating_volume\u001b[39m(points):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculates the 3D dominating volume of a set of points.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     hull \u001b[38;5;241m=\u001b[39m \u001b[43mConvexHull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hull\u001b[38;5;241m.\u001b[39mvolume\n",
      "File \u001b[0;32m_qhull.pyx:2489\u001b[0m, in \u001b[0;36mscipy.spatial._qhull.ConvexHull.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:352\u001b[0m, in \u001b[0;36mscipy.spatial._qhull._Qhull.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mQhullError\u001b[0m: QH6154 Qhull precision error: Initial simplex is flat (facet 1 is coplanar with the interior point)\n\nWhile executing:  | qhull i Qt\nOptions selected for Qhull 2019.1.r 2019/06/21:\n  run-id 1636645736  incidence  Qtriangulate  _pre-merge  _zero-centrum\n  _max-width  6  Error-roundoff 1.2e-14  _one-merge 8.7e-14\n  _near-inside 4.4e-13  Visible-distance 2.5e-14  U-max-coplanar 2.5e-14\n  Width-outside 5e-14  _wide-facet 1.5e-13  _maxoutside 1e-13\n\nprecision problems (corrected unless 'Q0' or an error)\n      4 degenerate hyperplanes recomputed with gaussian elimination\n      4 nearly singular or axis-parallel hyperplanes\n      4 zero divisors during back substitute\n      4 zero divisors during gaussian elimination\n\nThe input to qhull appears to be less than 3 dimensional, or a\ncomputation has overflowed.\n\nQhull could not construct a clearly convex simplex from points:\n- p3(v4):     2     3     4\n- p1(v3):     4     5     6\n- p2(v2):     7     8     9\n- p0(v1):     1     2     3\n\nThe center point is coplanar with a facet, or a vertex is coplanar\nwith a neighboring facet.  The maximum round off error for\ncomputing distances is 1.2e-14.  The center point, facets and distances\nto the center point are as follows:\n\ncenter point      3.5      4.5      5.5\n\nfacet p1 p2 p0 distance= -4.4e-16\nfacet p3 p2 p0 distance= -4.4e-16\nfacet p3 p1 p0 distance= -4.4e-16\nfacet p3 p1 p2 distance= -4.4e-16\n\nThese points either have a maximum or minimum x-coordinate, or\nthey maximize the determinant for k coordinates.  Trial points\nare first selected from points that maximize a coordinate.\n\nThe min and max coordinates for each dimension are:\n  0:         1         7  difference=    6\n  1:         2         8  difference=    6\n  2:         3         9  difference=    6\n\nIf the input should be full dimensional, you have several options that\nmay determine an initial simplex:\n  - use 'QJ'  to joggle the input and make it full dimensional\n  - use 'QbB' to scale the points to the unit cube\n  - use 'QR0' to randomly rotate the input for different maximum points\n  - use 'Qs'  to search all points for the initial simplex\n  - use 'En'  to specify a maximum roundoff error less than 1.2e-14.\n  - trace execution with 'T3' to see the determinant for each point.\n\nIf the input is lower dimensional:\n  - use 'QJ' to joggle the input and make it full dimensional\n  - use 'Qbk:0Bk:0' to delete coordinate k from the input.  You should\n    pick the coordinate with the least range.  The hull will have the\n    correct topology.\n  - determine the flat containing the points, rotate the points\n    into a coordinate plane, and delete the other coordinates.\n  - add one or more points to make the input full dimensional.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "def dominating_volume(points):\n",
    "    \"\"\"Calculates the 3D dominating volume of a set of points.\"\"\"\n",
    "\n",
    "    hull = ConvexHull(points)\n",
    "    return hull.volume\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example points (replace with your own data)\n",
    "    points = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [2, 3, 4]])\n",
    "\n",
    "    volume = dominating_volume(points)\n",
    "    print(\"Dominating volume:\", volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14400000000000002"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9*0.8*0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3656, 0.0426, 0.8780],\n",
       "        [0.3172, 0.8009, 0.8128],\n",
       "        [0.8329, 0.3663, 0.2522],\n",
       "        [0.8224, 0.9843, 0.6153],\n",
       "        [0.9936, 0.8647, 0.2721]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'good':2, 'bad':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "device = \"cpu\"\n",
    "model_id = \"openai-community/gpt2-large\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 71904.24 examples/s]\n",
      "Generating train split: 100%|██████████| 36718/36718 [00:00<00:00, 586910.37 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 389108.88 examples/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (287644 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"test\")\n",
    "encodings = tokenizer(\"\\n\\n\".join(test[\"text\"]), return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 56/57 [02:58<00:03,  3.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "max_length = model.config.n_positions\n",
    "stride = 5120\n",
    "seq_len = encodings.input_ids.size(1)\n",
    "\n",
    "nlls = []\n",
    "prev_end_loc = 0\n",
    "for begin_loc in tqdm(range(0, seq_len, stride)):\n",
    "    end_loc = min(begin_loc + max_length, seq_len)\n",
    "    trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
    "    target_ids = input_ids.clone()\n",
    "    target_ids[:, :-trg_len] = -100\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=target_ids)\n",
    "\n",
    "        # loss is calculated using CrossEntropyLoss which averages over valid labels\n",
    "        # N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels\n",
    "        # to the left by 1.\n",
    "        neg_log_likelihood = outputs.loss\n",
    "\n",
    "    nlls.append(neg_log_likelihood)\n",
    "\n",
    "    prev_end_loc = end_loc\n",
    "    if end_loc == seq_len:\n",
    "        break\n",
    "\n",
    "ppl = torch.exp(torch.stack(nlls).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(2.4563),\n",
       " tensor(3.2130),\n",
       " tensor(2.8298),\n",
       " tensor(3.1584),\n",
       " tensor(2.8602),\n",
       " tensor(3.0615),\n",
       " tensor(3.4675),\n",
       " tensor(2.8435),\n",
       " tensor(3.3761),\n",
       " tensor(3.2331),\n",
       " tensor(3.3443),\n",
       " tensor(2.6687),\n",
       " tensor(2.5851),\n",
       " tensor(2.6306),\n",
       " tensor(2.2679),\n",
       " tensor(2.2570),\n",
       " tensor(3.4688),\n",
       " tensor(3.1651),\n",
       " tensor(3.1864),\n",
       " tensor(2.9431),\n",
       " tensor(2.8955),\n",
       " tensor(2.7686),\n",
       " tensor(2.8608),\n",
       " tensor(3.1048),\n",
       " tensor(3.1405),\n",
       " tensor(2.4870),\n",
       " tensor(2.5494),\n",
       " tensor(2.4721),\n",
       " tensor(2.9212),\n",
       " tensor(3.0260),\n",
       " tensor(2.8389),\n",
       " tensor(3.2759),\n",
       " tensor(2.5990),\n",
       " tensor(2.6903),\n",
       " tensor(2.9425),\n",
       " tensor(3.5460),\n",
       " tensor(3.0721),\n",
       " tensor(2.6845),\n",
       " tensor(3.0366),\n",
       " tensor(2.9020),\n",
       " tensor(3.0449),\n",
       " tensor(3.5175),\n",
       " tensor(2.8849),\n",
       " tensor(2.8323),\n",
       " tensor(3.3599),\n",
       " tensor(2.9644),\n",
       " tensor(3.0535),\n",
       " tensor(2.7922),\n",
       " tensor(3.0178),\n",
       " tensor(3.0856),\n",
       " tensor(2.6764),\n",
       " tensor(2.9691),\n",
       " tensor(2.5791),\n",
       " tensor(1.8262),\n",
       " tensor(3.3218),\n",
       " tensor(2.8275),\n",
       " tensor(2.8636)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.5434)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.6973828673362732}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the TextAttack CoLA RoBERTa model\n",
    "classifier = pipeline(\"text-classification\", model=\"textattack/roberta-base-CoLA\")\n",
    "\n",
    "# Test with a sentence\n",
    "sentence = \"afha;i apoifjap efn; paoijfjnpe f; p;infaie f\"\n",
    "result = classifier(sentence)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, GPT2LMHeadModel, AutoModelForSequenceClassification, GPT2Tokenizer\n",
    "from typing import List, Dict, Optional, Tuple, Union, Any\n",
    "from collections import defaultdict\n",
    "from rlprompt.rewards import BaseReward\n",
    "\n",
    "SUPPORTED_LEFT_TO_RIGHT_LMS = ['distilgpt2', 'gpt2', 'gpt2-medium',\n",
    "                               'gpt2-large', 'gpt2-xl']\n",
    "SUPPORTED_MASK_LMS = ['distilroberta-base', 'roberta-base', 'roberta-large']\n",
    "\n",
    "# def perplexity_calculate2(input_text):\n",
    "#     model_name = \"gpt2\"\n",
    "#     tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "#     model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "#     # Set the model to evaluation mode\n",
    "#     model.eval()\n",
    "\n",
    "#     # Tokenize the input\n",
    "#     input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "#     # Get the model's output (logits and loss)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids, labels=input_ids)\n",
    "#         loss = outputs.loss\n",
    "\n",
    "#     # Calculate perplexity\n",
    "#     perplexity = torch.exp(loss)\n",
    "#     return perplexity\n",
    "\n",
    "\n",
    "# model_name_p = \"textattack/roberta-base-CoLA\"\n",
    "# tokenizer_p = AutoTokenizer.from_pretrained(model_name_p)\n",
    "# model_p = AutoModelForSequenceClassification.from_pretrained(model_name_p)\n",
    "# model_p.eval()\n",
    "\n",
    "def perplexity_calculate(input_text, model_name_p, model_p, tokenizer_p):\n",
    "\n",
    "    \n",
    "    if model_name_p == \"textattack/roberta-base-CoLA\":\n",
    "        # Input sentence\n",
    "        sentence = input_text\n",
    "\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer_p(sentence, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model_p(**inputs)\n",
    "\n",
    "            # Get prediction (logits)\n",
    "            logits = outputs.logits\n",
    "            probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        # Probability that the sentence is acceptable\n",
    "        acceptability_score = probabilities[0][1].item()\n",
    "        return torch.tensor(acceptability_score)\n",
    "    \n",
    "    elif model_name_p == \"gpt2\":\n",
    "        input_ids = tokenizer_p.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "        # Get the model's output (logits and loss)\n",
    "        with torch.no_grad():\n",
    "            outputs = model_p(input_ids, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "\n",
    "        # Calculate perplexity\n",
    "        perplexity = torch.log(loss)\n",
    "        return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_p = \"textattack/roberta-base-CoLA\"\n",
    "tokenizer_p = AutoTokenizer.from_pretrained(model_name_p)\n",
    "model_p = AutoModelForSequenceClassification.from_pretrained(model_name_p)\n",
    "model_p.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/pscratch/sd/g/gzhao27/rl-prompt/examples/few-shot-classification/string_record.txt\", 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "value1 = []\n",
    "value2 = []\n",
    "i = 0\n",
    "for line in lines:\n",
    "    v1 = perplexity_calculate(line, model_name_p, model_p, tokenizer_p)\n",
    "    v2 = perplexity_calculate(line, model_name, model, tokenizer)\n",
    "    value1.append(v1)\n",
    "    value2.append(v2)\n",
    "    i+=1\n",
    "    if i > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "value3 = []\n",
    "for a in value2:\n",
    "    value3.append(torch.exp(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "value4 = []\n",
    "for a in value3:\n",
    "    value4.append(torch.exp(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(value1, value4)\n",
    "plt.xlabel('Linguistic Acceptability Score (CoLA)')\n",
    "plt.ylabel('Perplexity (GPT2)')\n",
    "plt.yscale('log')\n",
    "# plt.ylim(0, 00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman's Rank Correlation Coefficient: -0.4739961656844198\n",
      "p-value: 3.3317966863192103e-57\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Calculate Spearman's Rank Correlation Coefficient\n",
    "corr_coefficient, p_value = spearmanr(value1, value4)\n",
    "\n",
    "# Print results\n",
    "print(\"Spearman's Rank Correlation Coefficient:\", corr_coefficient)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient: -0.26829822221327715\n",
      "p-value: 5.7806314e-18\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "correlation, p_value = pearsonr(value1, value4)\n",
    "correlation = np.corrcoef(value1, value4)[0, 1]\n",
    "print(\"Correlation coefficient:\", correlation)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.23.5 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from scipy) (1.26.4)\n",
      "Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m225.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.savefig('LAS-perplexity.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000, 0.4197, 0.6587, 0.3655, 0.6452])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'key1': 'value1', 'key2': 'value2'}\n",
    "object1_value, object2_value = my_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "key1, key2 = my_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'key1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grammatical correctness score: 0.1069\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"textattack/roberta-base-CoLA\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Input sentence\n",
    "sentence = \"METHODSpawnrolog)</ condem\"\n",
    "\n",
    "# Tokenize input\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Get prediction (logits)\n",
    "logits = outputs.logits\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "# Probability that the sentence is acceptable\n",
    "acceptability_score = probabilities[0][1].item()\n",
    "print(f\"Grammatical correctness score: {acceptability_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity_calculate(input_text):\n",
    "\n",
    "    model_name = \"textattack/roberta-base-CoLA\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    # Input sentence\n",
    "    sentence = input_text\n",
    "\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Get prediction (logits)\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "    # Probability that the sentence is acceptable\n",
    "    acceptability_score = probabilities[0][1].item()\n",
    "    return acceptability_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5012895464897156"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_calculate('aerjnje i;qeir h dakfhqei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import RobertaForMaskedLM, AutoTokenizer, AutoConfig\n",
    "\n",
    "class Perplexity(object):\n",
    "    def __init__(self, model=\"roberta-base\", device=\"cuda\"):\n",
    "        assert model, \"The model must not be None\"\n",
    "        self.device = torch.device('cuda')\n",
    "        pretrained_config = AutoConfig.from_pretrained(model)\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "        self.mlm = RobertaForMaskedLM(pretrained_config).to(self.device)\n",
    "\n",
    "    def calculate_perplexity(self, prompt):\n",
    "        inputs = self.tokenizer(\n",
    "            str(prompt), return_tensors=\"pt\", truncation=True, padding=True\n",
    "        )\n",
    "        inputs = inputs.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.mlm(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            # perplexity = torch.exp(loss)\n",
    "            perplexity = torch.exp(loss / inputs[\"input_ids\"].size(1))\n",
    "\n",
    "        return perplexity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = Perplexity()\n",
    "perplexity_calculate = pe.calculate_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting optimum[onnxruntime-gpu]\n",
      "  Downloading optimum-1.22.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting coloredlogs (from optimum[onnxruntime-gpu])\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (1.13.0)\n",
      "Requirement already satisfied: transformers<4.45.0,>=4.29 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from transformers[sentencepiece]<4.45.0,>=4.29->optimum[onnxruntime-gpu]) (4.42.3)\n",
      "Requirement already satisfied: torch>=1.11 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (2.3.1)\n",
      "Requirement already satisfied: packaging in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (24.1)\n",
      "Requirement already satisfied: numpy<2.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (0.23.4)\n",
      "Collecting datasets (from optimum[onnxruntime-gpu])\n",
      "  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting onnx (from optimum[onnxruntime-gpu])\n",
      "  Downloading onnx-1.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime-gpu>=1.11.0 (from optimum[onnxruntime-gpu])\n",
      "  Downloading onnxruntime_gpu-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting evaluate (from optimum[onnxruntime-gpu])\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.1 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (5.27.2)\n",
      "Requirement already satisfied: accelerate in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from optimum[onnxruntime-gpu]) (0.34.2)\n",
      "Requirement already satisfied: filelock in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from datasets->optimum[onnxruntime-gpu]) (3.15.4)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from datasets->optimum[onnxruntime-gpu]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from datasets->optimum[onnxruntime-gpu]) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from datasets->optimum[onnxruntime-gpu]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from datasets->optimum[onnxruntime-gpu]) (4.66.4)\n",
      "Collecting xxhash (from datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->optimum[onnxruntime-gpu]) (2024.6.1)\n",
      "Collecting aiohttp (from datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading aiohttp-3.10.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from datasets->optimum[onnxruntime-gpu]) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from huggingface-hub>=0.8.0->optimum[onnxruntime-gpu]) (4.12.2)\n",
      "Collecting flatbuffers (from onnxruntime-gpu>=1.11.0->optimum[onnxruntime-gpu])\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: networkx in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (3.3)\n",
      "Requirement already satisfied: jinja2 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from torch>=1.11->optimum[onnxruntime-gpu]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum[onnxruntime-gpu]) (12.5.82)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum[onnxruntime-gpu]) (2024.5.15)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum[onnxruntime-gpu]) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from transformers<4.45.0,>=4.29->transformers[sentencepiece]<4.45.0,>=4.29->optimum[onnxruntime-gpu]) (0.19.1)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.45.0,>=4.29->optimum[onnxruntime-gpu])\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: psutil in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from accelerate->optimum[onnxruntime-gpu]) (5.9.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum[onnxruntime-gpu])\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from sympy->optimum[onnxruntime-gpu]) (1.3.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from aiohttp->datasets->optimum[onnxruntime-gpu]) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->optimum[onnxruntime-gpu])\n",
      "  Downloading yarl-1.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from requests>=2.32.2->datasets->optimum[onnxruntime-gpu]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from requests>=2.32.2->datasets->optimum[onnxruntime-gpu]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from requests>=2.32.2->datasets->optimum[onnxruntime-gpu]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from requests>=2.32.2->datasets->optimum[onnxruntime-gpu]) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from jinja2->torch>=1.11->optimum[onnxruntime-gpu]) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from pandas->datasets->optimum[onnxruntime-gpu]) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from pandas->datasets->optimum[onnxruntime-gpu]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from pandas->datasets->optimum[onnxruntime-gpu]) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /global/homes/g/gzhao27/anaconda3/envs/Prompt/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum[onnxruntime-gpu]) (1.16.0)\n",
      "Downloading datasets-3.0.0-py3-none-any.whl (474 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.3/474.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime_gpu-1.19.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m205.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m269.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m316.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnx-1.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m332.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading optimum-1.22.0-py3-none-any.whl (453 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.7/453.7 kB\u001b[0m \u001b[31m375.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.10.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m393.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m318.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-17.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (39.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m326.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m323.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m345.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m364.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 kB\u001b[0m \u001b[31m372.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m316.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.1/489.1 kB\u001b[0m \u001b[31m384.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, flatbuffers, xxhash, pyarrow, onnx, multiprocess, multidict, humanfriendly, frozenlist, aiohappyeyeballs, yarl, coloredlogs, aiosignal, onnxruntime-gpu, aiohttp, datasets, optimum, evaluate\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 coloredlogs-15.0.1 datasets-3.0.0 evaluate-0.4.3 flatbuffers-24.3.25 frozenlist-1.4.1 humanfriendly-10.0 multidict-6.1.0 multiprocess-0.70.16 onnx-1.16.2 onnxruntime-gpu-1.19.2 optimum-1.22.0 pyarrow-17.0.0 sentencepiece-0.2.0 xxhash-3.5.0 yarl-1.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install optimum[onnxruntime-gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.9684914350509644}, {'label': 'LABEL_1', 'score': 0.7473592758178711}, {'label': 'LABEL_1', 'score': 0.6991557478904724}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from optimum.onnxruntime import ORTModelForSequenceClassification\n",
    "from optimum.pipelines import pipeline\n",
    "\n",
    "# load tokenizer and model weights\n",
    "tokenizer = AutoTokenizer.from_pretrained('Deepchecks/parrot_fluency_model_onnx')\n",
    "model = ORTModelForSequenceClassification.from_pretrained('Deepchecks/parrot_fluency_model_onnx')\n",
    "\n",
    "# prepare the pipeline and generate inferences\n",
    "user_inputs = ['Natural language processing is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence.',\n",
    "               'Pass on what you have learned. Strength, mastery, hmm… but weakness, folly, failure, also. Yes, failure, most of all. The greatest teacher, failure is.',\n",
    "               'Pros wonderful']\n",
    "pip = pipeline(task='text-classification', model=model, tokenizer=tokenizer, device=torch.device('cpu'), accelerator=\"ort\")\n",
    "res = pip(user_inputs, batch_size=64, truncation=\"only_first\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "\n",
    "def perplexity_calculate(input_text):\n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the input\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Get the model's output (logits and loss)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "    # Calculate perplexity\n",
    "    perplexity = torch.exp(loss)\n",
    "    print(f\"Perplexity: {perplexity.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Square Game Quality In Credit'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prlist = ['Square', 'Game', 'Quality', 'ĠIn', 'Credit']\n",
    "\" \".join([token.replace('Ġ', '') for token in prlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 39076.05078125\n"
     ]
    }
   ],
   "source": [
    "perplexity_calculate('Bytes Zero Share Alert Leader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.370862007141113"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_calculate('Pros wonderful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.820967197418213"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_calculate('I like you so much')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there used to be a separate society for Sylph, Sylvanas, Azmodan, Echargerated Kilrathi, zenkins and nature mages. Within that latter group, however, there is a split as well about\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "model_name = 'gpt2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "input_text = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Generate text with sampling\n",
    "output = model.generate(input_ids, max_length=50, do_sample=True, top_k=0)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "yx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "z = torch.tensor(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "losses1 = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(0.0, requires_grad=True).grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.to(z.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto dominant volume: 36.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def pareto_dominant_volume(sample_points, reference_point):\n",
    "    \"\"\"\n",
    "    Calculate the Pareto dominant volume of sample points with respect to a reference point.\n",
    "    \n",
    "    Args:\n",
    "    - sample_points (torch.Tensor): Tensor of size N*2 containing N sample points.\n",
    "    - reference_point (torch.Tensor): Tensor of size 2 containing the reference point.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Pareto dominant volume.\n",
    "    \"\"\"\n",
    "    # Calculate the number of sample points\n",
    "    num_points = sample_points.size(0)\n",
    "    \n",
    "    # Calculate the number of dimensions\n",
    "    num_dimensions = sample_points.size(1)\n",
    "    \n",
    "    # Initialize a counter for dominated points\n",
    "    dominated_count = 0\n",
    "    \n",
    "    # Iterate through each sample point\n",
    "    for i in range(num_points):\n",
    "        # Check if the sample point dominates the reference point\n",
    "        if torch.all(sample_points[i] <= reference_point):\n",
    "            # Increment the counter for dominated points\n",
    "            dominated_count += 1\n",
    "    \n",
    "    # Calculate the ratio of dominated points to total points\n",
    "    dominance_ratio = dominated_count / num_points\n",
    "    \n",
    "    # Calculate the Pareto dominant volume (area in 2D)\n",
    "    pareto_volume = dominance_ratio * (reference_point[0] - sample_points[:, 0].min()) * (reference_point[1] - sample_points[:, 1].min())\n",
    "    \n",
    "    return pareto_volume\n",
    "\n",
    "# Example usage:\n",
    "sample_points = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "reference_point = torch.tensor([7.0, 8.0])\n",
    "\n",
    "pareto_volume = pareto_dominant_volume(sample_points, reference_point)\n",
    "print(\"Pareto dominant volume:\", pareto_volume.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 3]\n",
      " [3 4]\n",
      " [4 5]\n",
      " [5 6]]\n",
      "Hypervolume Indicator: 15.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import array\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Example Pareto front (list of solutions with two objectives)\n",
    "pareto_front = [(1, 2), (2, 3), (3, 4), (4, 5), (5, 6)]\n",
    "\n",
    "# Function to calculate hypervolume indicator\n",
    "def hypervolume_indicator(pareto_front, ref_point):\n",
    "    \"\"\"\n",
    "    Calculate hypervolume indicator for a Pareto front and reference point.\n",
    "    \n",
    "    :param pareto_front: List of Pareto optimal solutions.\n",
    "    :param ref_point: Reference point for hypervolume calculation.\n",
    "    :return: Hypervolume indicator value.\n",
    "    \"\"\"\n",
    "    # Convert pareto front and reference point to numpy arrays\n",
    "    pareto_front = np.array(pareto_front)\n",
    "    ref_point = np.array(ref_point)\n",
    "    \n",
    "    # Sort Pareto front based on first objective (ascending order)\n",
    "    pareto_front = pareto_front[np.argsort(pareto_front[:, 0])]\n",
    "    print(pareto_front)\n",
    "    # Initialize hypervolume\n",
    "    hypervolume = 0.0\n",
    "    \n",
    "    # Iterate through solutions in Pareto front\n",
    "    for i in range(len(pareto_front)):\n",
    "        # Calculate hypervolume contribution of current solution\n",
    "        if i == 0:\n",
    "            hypervolume += (ref_point[0] - pareto_front[i][0]) * (ref_point[1] - pareto_front[i][1])\n",
    "        else:\n",
    "            hypervolume += (pareto_front[i-1][0] - pareto_front[i][0]) * (ref_point[1] - pareto_front[i][1])\n",
    "    \n",
    "    return hypervolume\n",
    "\n",
    "# Reference point for hypervolume calculation (maximum values for each objective)\n",
    "reference_point = (6, 7)\n",
    "\n",
    "# Calculate hypervolume indicator\n",
    "hv = hypervolume_indicator(pareto_front, reference_point)\n",
    "print(\"Hypervolume Indicator:\", hv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto dominant volume: 42.0\n"
     ]
    }
   ],
   "source": [
    "sample_points = torch.tensor([[1.0, 2.0], [2.0, 1.0], [5.0, 6.0]])\n",
    "reference_point = torch.tensor([7.0, 8.0])\n",
    "\n",
    "pareto_volume = pareto_dominant_volume(sample_points, reference_point)\n",
    "print(\"Pareto dominant volume:\", pareto_volume.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pareto_dominance_volume(sample_points, reference_point):\n",
    "    # Calculate the minimum and maximum x and y values\n",
    "    min_x = torch.min(sample_points[:, 0])\n",
    "    max_x = torch.max(sample_points[:, 0])\n",
    "    min_y = torch.min(sample_points[:, 1])\n",
    "    max_y = torch.max(sample_points[:, 1])\n",
    "    \n",
    "    # Calculate the area dominated by the sample points and also dominating the reference point\n",
    "    dominate_volume = (max_x - min_x) * (max_y - min_y)\n",
    "    \n",
    "    # Check if the reference point is dominated by the sample points\n",
    "    if (reference_point[0] >= min_x) and (reference_point[0] <= max_x) and (reference_point[1] >= min_y) and (reference_point[1] <= max_y):\n",
    "        dominate_volume -= (reference_point[0] - min_x) * (reference_point[1] - min_y)\n",
    "    \n",
    "    return dominate_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_dominant_volume(sample_points, reference_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto dominant volume: 36.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def pareto_dominant_volume(sample_points, reference_point):\n",
    "    \"\"\"\n",
    "    Calculate the Pareto dominant volume of sample points with respect to a reference point.\n",
    "    \n",
    "    Args:\n",
    "    - sample_points (torch.Tensor): Tensor of size N*2 containing N sample points.\n",
    "    - reference_point (torch.Tensor): Tensor of size 2 containing the reference point.\n",
    "    \n",
    "    Returns:\n",
    "    - float: Pareto dominant volume.\n",
    "    \"\"\"\n",
    "    # Calculate the number of sample points\n",
    "    num_points = sample_points.size(0)\n",
    "    \n",
    "    # Calculate the number of dimensions\n",
    "    num_dimensions = sample_points.size(1)\n",
    "    \n",
    "    # Initialize a counter for dominating points\n",
    "    dominating_count = 0\n",
    "    \n",
    "    # Iterate through each sample point\n",
    "    for i in range(num_points):\n",
    "        # Check if the sample point is dominated by the reference point\n",
    "        if torch.all(sample_points[i] <= reference_point):\n",
    "            # Increment the counter for dominating points\n",
    "            dominating_count += 1\n",
    "    \n",
    "    # Calculate the ratio of dominating points to total points\n",
    "    dominance_ratio = dominating_count / num_points\n",
    "    \n",
    "    # Calculate the Pareto dominant volume (area in 2D)\n",
    "    pareto_volume = dominance_ratio * (reference_point[0] - sample_points[:, 0].min()) * (reference_point[1] - sample_points[:, 1].min())\n",
    "    \n",
    "    return pareto_volume\n",
    "\n",
    "# Example usage:\n",
    "sample_points = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "reference_point = torch.tensor([7.0, 8.0])\n",
    "\n",
    "pareto_volume = pareto_dominant_volume(sample_points, reference_point)\n",
    "print(\"Pareto dominant volume:\", pareto_volume.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def pareto_dominate_volume(sample_points, reference_point):\n",
    "  \"\"\"\n",
    "  Calculates the Pareto dominate volume of sample points with respect to a reference point.\n",
    "\n",
    "  Args:\n",
    "      sample_points: A torch tensor of size (N, 2) representing the sample points.\n",
    "      reference_point: A torch tensor of size (2) representing the reference point.\n",
    "\n",
    "  Returns:\n",
    "      A float representing the Pareto dominate volume.\n",
    "  \"\"\"\n",
    "  # Check for valid input shapes\n",
    "  if sample_points.dim() != 2 or sample_points.shape[1] != 2:\n",
    "    raise ValueError(\"sample_points must be a tensor of size (N, 2)\")\n",
    "  if reference_point.dim() != 1 or reference_point.shape[0] != 2:\n",
    "    raise ValueError(\"reference_point must be a tensor of size (2)\")\n",
    "\n",
    "  # Calculate the number of dimensions (objectives)\n",
    "  num_objectives = sample_points.shape[1]\n",
    "\n",
    "  # Calculate boolean mask for points dominating the reference point in all dimensions\n",
    "  dominates_reference = torch.all(sample_points < reference_point, dim=1)\n",
    "\n",
    "  # Calculate boolean mask for points not dominated by any other sample point\n",
    "  not_dominated = torch.ones(sample_points.shape[0], dtype=bool)\n",
    "  for i in range(sample_points.shape[0]):\n",
    "    current_point = sample_points[i]\n",
    "    other_points = torch.cat((sample_points[:i], sample_points[i+1:]), dim=0)\n",
    "    not_dominated[i] = torch.any(~torch.all(other_points <= current_point, dim=1))\n",
    "\n",
    "  # Calculate the final mask for points in the Pareto dominate volume\n",
    "  pareto_dominate = dominates_reference & not_dominated\n",
    "\n",
    "  # Calculate the area (assuming minimization problems) by summing dominated objective differences\n",
    "  dominate_volume = torch.sum(torch.where(pareto_dominate, reference_point - sample_points, torch.zeros_like(sample_points)))\n",
    "\n",
    "  return dominate_volume.item()  # Return the scalar value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpareto_dominate_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 37\u001b[0m, in \u001b[0;36mpareto_dominate_volume\u001b[0;34m(sample_points, reference_point)\u001b[0m\n\u001b[1;32m     34\u001b[0m pareto_dominate \u001b[38;5;241m=\u001b[39m dominates_reference \u001b[38;5;241m&\u001b[39m not_dominated\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Calculate the area (assuming minimization problems) by summing dominated objective differences\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m dominate_volume \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpareto_dominate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_point\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample_points\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_points\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dominate_volume\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "pareto_dominate_volume(sample_points, reference_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pareto Front:\n",
      "tensor([[1, 2]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_pareto_front(samples):\n",
    "    \"\"\"\n",
    "    Find the Pareto front of given sample points.\n",
    "    \n",
    "    :param samples: Torch tensor of size N*2 containing sample points (N samples, 2 objectives).\n",
    "    :return: List of indices of points in the Pareto front.\n",
    "    \"\"\"\n",
    "    pareto_front = []\n",
    "    dominated_by = torch.zeros(samples.size(0), dtype=torch.bool)\n",
    "    \n",
    "    for i, point1 in enumerate(samples):\n",
    "        if not dominated_by[i]:\n",
    "            pareto_front.append(i)\n",
    "            for j, point2 in enumerate(samples):\n",
    "                if i != j:\n",
    "                    if torch.all(point1 <= point2):\n",
    "                        dominated_by[j] = True\n",
    "                    elif torch.all(point1 >= point2):\n",
    "                        dominated_by[i] = True\n",
    "                        pareto_front.remove(i)\n",
    "                        break\n",
    "                        \n",
    "    return pareto_front\n",
    "\n",
    "# Example sample points (torch tensor of size N*2)\n",
    "samples = torch.tensor([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])\n",
    "\n",
    "# Find Pareto front\n",
    "pareto_front_indices = find_pareto_front(samples)\n",
    "\n",
    "# Print Pareto front\n",
    "pareto_front = samples[pareto_front_indices]\n",
    "print(\"Pareto Front:\")\n",
    "print(pareto_front)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 2.0000],\n",
      "        [1.2000, 1.7000],\n",
      "        [1.5000, 1.5000],\n",
      "        [2.0000, 1.0000]])\n",
      "tensor([1., 0.])\n",
      "tensor([1.2000, 0.0000])\n",
      "tensor([1.5000, 0.0000])\n",
      "tensor([2., 0.])\n",
      "Dominating Volume: tensor(3.2900)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_pareto_front(samples):\n",
    "    \"\"\"\n",
    "    Find the Pareto front of given sample points.\n",
    "    \n",
    "    :param samples: Torch tensor of size N*2 containing sample points (N samples, 2 objectives).\n",
    "    :return: List of indices of points in the Pareto front.\n",
    "    \"\"\"\n",
    "    pareto_front = []\n",
    "    dominated_by = torch.zeros(samples.size(0), dtype=torch.bool)\n",
    "    \n",
    "    for i, point1 in enumerate(samples):\n",
    "        if not dominated_by[i]:\n",
    "            pareto_front.append(i)\n",
    "            for j, point2 in enumerate(samples):\n",
    "                if i != j:\n",
    "                    if torch.all(point1 >= point2):\n",
    "                        dominated_by[j] = True\n",
    "                    elif torch.all(point1 <= point2):\n",
    "                        dominated_by[i] = True\n",
    "                        pareto_front.remove(i)\n",
    "                        break\n",
    "    PF = samples[pareto_front]\n",
    "    return PF\n",
    "\n",
    "def calculate_dominating_volume(pareto_front, ref_point):\n",
    "    \"\"\"\n",
    "    Calculate the dominating volume of the Pareto front with respect to a reference point.\n",
    "    \n",
    "    :param pareto_front: Torch tensor of size N*2 containing points in the Pareto front (N points, 2 objectives).\n",
    "    :param ref_point: Torch tensor of size 2 representing the reference point.\n",
    "    :return: Dominating volume of the Pareto front.\n",
    "    \"\"\"\n",
    "    # Sort Pareto front based on the first objective (ascending order)\n",
    "    sorted_pareto_front = pareto_front[pareto_front[:, 0].argsort()]\n",
    "    \n",
    "    # Initialize dominating volume\n",
    "    dominating_volume = 0.0\n",
    "    \n",
    "    # Initialize the right upper corner of the rectangle\n",
    "    right_upper_corner = ref_point.clone()\n",
    "    print(sorted_pareto_front)\n",
    "    # Iterate through sorted Pareto front\n",
    "    for point in sorted_pareto_front:\n",
    "        # Calculate the width and height of the rectangle\n",
    "        width = right_upper_corner[0] - point[0]\n",
    "        height = right_upper_corner[1] - point[1]\n",
    "        \n",
    "        # Update dominating volume by adding the area of the rectangle\n",
    "        dominating_volume += width * height\n",
    "        \n",
    "        # Update the right upper corner for the next rectangle\n",
    "        right_upper_corner[0] = point[0]\n",
    "        print(right_upper_corner)\n",
    "    \n",
    "    return dominating_volume\n",
    "\n",
    "# Example sample points (torch tensor of size N*2)\n",
    "samples = torch.tensor([[1, 2], [2, 1], [2, 1], [1.2, 1.7], [1.5, 1.5]])\n",
    "\n",
    "# Find Pareto front\n",
    "pareto_front_indices = find_pareto_front(samples)\n",
    "# pareto_front = samples[pareto_front_indices]\n",
    "\n",
    "# Reference point (torch tensor of size 2)\n",
    "reference_point =torch.tensor([.0, .0])\n",
    "\n",
    "# Calculate dominating volume\n",
    "dominating_volume = calculate_dominating_volume(pareto_front, reference_point)\n",
    "\n",
    "# Print dominating volume\n",
    "print(\"Dominating Volume:\", dominating_volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dominating Volume: tensor(15.3400)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_pareto_front(samples):\n",
    "    \"\"\"\n",
    "    Find the Pareto front of given sample points.\n",
    "    \n",
    "    :param samples: Torch tensor of size N*2 containing sample points (N samples, 2 objectives).\n",
    "    :return: Pareto front as a torch tensor.\n",
    "    \"\"\"\n",
    "    pareto_front = []\n",
    "    dominated_by = torch.zeros(samples.size(0), dtype=torch.bool)\n",
    "    \n",
    "    for idx, point1 in enumerate(samples):\n",
    "        if not dominated_by[idx]:\n",
    "            pareto_front.append(idx)\n",
    "            for j, point2 in enumerate(samples):\n",
    "                if idx != j:\n",
    "                    if torch.all(point1 <= point2):\n",
    "                        dominated_by[j] = True\n",
    "                    elif torch.all(point1 >= point2):\n",
    "                        dominated_by[idx] = True\n",
    "                        pareto_front.remove(idx)\n",
    "                        break\n",
    "    pareto_front_tensor = samples[pareto_front]\n",
    "    return pareto_front_tensor\n",
    "\n",
    "def calculate_dominating_volume(pareto_front, ref_point):\n",
    "    \"\"\"\n",
    "    Calculate the dominating volume of the Pareto front with respect to a reference point.\n",
    "    \n",
    "    :param pareto_front: Torch tensor of size N*2 containing points in the Pareto front (N points, 2 objectives).\n",
    "    :param ref_point: Torch tensor of size 2 representing the reference point.\n",
    "    :return: Dominating volume of the Pareto front.\n",
    "    \"\"\"\n",
    "    # Sort Pareto front based on the first objective (ascending order)\n",
    "    sorted_pareto_front = pareto_front[pareto_front[:, 0].argsort()]\n",
    "    \n",
    "    # Initialize dominating volume\n",
    "    dominating_volume = 0.0\n",
    "    \n",
    "    # Initialize the upper left corner of the rectangle\n",
    "    upper_left_corner = ref_point.clone()\n",
    "    \n",
    "    # Iterate through sorted Pareto front\n",
    "    for point in sorted_pareto_front:\n",
    "        # Calculate the width and height of the rectangle\n",
    "        width = upper_left_corner[0] - point[0]\n",
    "        height = upper_left_corner[1] - point[1]\n",
    "        \n",
    "        # Update dominating volume by adding the area of the rectangle\n",
    "        dominating_volume += width * height\n",
    "        \n",
    "        # Update the upper left corner for the next rectangle\n",
    "        upper_left_corner[1] = point[1]\n",
    "    \n",
    "    return dominating_volume\n",
    "\n",
    "# Example sample points (torch tensor of size N*2)\n",
    "samples = torch.tensor([[1, 2], [2, 1], [3, 3], [1.2, 1.7], [1.5, 1.5]])\n",
    "\n",
    "# Find Pareto front\n",
    "pareto_front_tensor = find_pareto_front(samples)\n",
    "\n",
    "# Reference point (torch tensor of size 2)\n",
    "reference_point = torch.tensor([5.0, 5.0])\n",
    "\n",
    "# Calculate dominating volume\n",
    "dominating_volume = calculate_dominating_volume(pareto_front_tensor, reference_point)\n",
    "\n",
    "# Print dominating volume\n",
    "print(\"Dominating Volume:\", dominating_volume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_front_indices = find_pareto_front(samples)\n",
    "pareto_front = samples[pareto_front_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 2.0000],\n",
       "        [1.2000, 1.7000],\n",
       "        [1.5000, 1.5000],\n",
       "        [2.0000, 1.0000]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto_front[pareto_front[:, 0].argsort()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
